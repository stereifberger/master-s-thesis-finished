{"cells":[{"cell_type":"markdown","metadata":{"id":"H1s-09Vehuyh"},"source":["## 1 Overview\n","An enviroment to train and evaluate neural networks on learning logical consequence."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b99_Jd5Shuyl"},"outputs":[],"source":["# For Google Collab: Get repository and go to it in collab.\n","!git clone https://github.com/stereifberger/master-s-thesis-finished\n","%cd /content/master-s-thesis-finished/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1J3S28phuyo"},"outputs":[],"source":["# For VsCode after starting Jupyter server: go to right directory.\n","%cd master-s-thesis-finished/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p10NJvfLhuyq"},"outputs":[],"source":["# Install required dependencies - not necessary on google colab\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mw_X2CVshuyr"},"outputs":[],"source":["# Import required libraries\n","from imports import *"]},{"cell_type":"markdown","metadata":{"id":"YF06mLyghuyt"},"source":["## 2 Create dataset\n","First the dataset for training is generated. For this the function \"create_dataset\" from \"generation.py\" utilizes the functions \"get_conclusions\" to generate a set of random starting formulas, for which iterativly the applicability of rules is checked. All applicable rules are then used to generate new derivations. In each iteration of get_conclusions, set by the iterations variable, new, longer examples are generated.\n","\n","**Rules.** The rules are defined in calculi.py. Two sets are avaiable: Intuitionistic propositional logic (set below via \"calculus = ipl\") and classical propositional logic (set below via \"calculus = cl\").\n","\n","**Dataset entries.**\n","- **x_train.** Training input: [INDEX, PREMISES,CONCLUSION]\n","- **y_train_ordered.** Dataset of correct derivations where each sublist i correspnds to INDEX: [DERIVATIONS_0...DERIVATION_N]\n","\n","**Encoding.** Propositional variables and logical constants are encoded as integers.\n","\n","**Example entries withouth numerical representation and one-hot-encoding.**\n","- **x_train.** [2345, A, A THEN B, DERIVES, B OR C]\n","- **y_train_ordered.** Sublist 2345 is entry entry: [[A, A THEN B, B, B OR C], [A, A THEN B, B, A AND B, B OR C]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6LxyeZ4huyu"},"outputs":[],"source":["# Create dataset\n","x_train_2d, x_train_3d, y_train_ordered, max_y_train_len = generation.create_dataset(iterations = [1,2], calculus = calculi.cl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJk4GOnghuyv"},"outputs":[],"source":["import json\n","torch.save(x_train_2d, 'x_train_2d.pt')\n","torch.save(x_train_3d, 'x_train_3d.pt')\n","torch.save(y_train_ordered, 'y_train_ordered.pt')\n","with open('Medium_max_y_train_len.json', 'w') as file:\n","    json.dump(max_y_train_len, file)"]},{"cell_type":"markdown","metadata":{"id":"SzOk_Rpohuyw"},"source":["## 3 Prepare dataset and define models for training\n","Next with pytorch's dataloader the single training entries in x_train are assigned to batches of size \"batch size\" in mixed order. Then the different models are defined using definitions from \"architectures.py\". These models are:\n","\n","- Feedforward network (net)\n","- Recurrent neural network (RNNNet)\n","- Long-short-term memory (LSTMNet)\n","- Transformers (TransformerModel)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"paISqUDxhuyw"},"outputs":[],"source":["# Use when gpu is present to empty its catch and define it as \"device\" for referencing it\n","torch.cuda.empty_cache()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJHK5VSBhuyx"},"outputs":[],"source":["# Get the datasets' shapes for the model definitions later\n","two_d_shape = x_train_2d.shape\n","three_d_shape = x_train_3d.shape\n","max_y_length = int(max_y_train_len/14)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oTDj3oOAhuyx"},"outputs":[],"source":["# Reverse one-hot encoding for encoder-decoder models\n","x = torch.argmax(x_train_3d, dim=2)\n","x[:, 0] = x_train_2d[:, 0]\n","x_train_nu = x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXRSmVPChuyy"},"outputs":[],"source":["# Set train-test split to 80-20 [^1]\n","train_size = int(0.8 * len(x_train_2d))\n","test_size = len(x_train_2d) - train_size\n","x_train_2d, x_test_2d = random_split(x_train_2d, [train_size, test_size])\n","x_train_3d, x_test_3d = random_split(x_train_3d, [train_size, test_size])\n","x_train_nu, x_test_nu = random_split(x_train_nu, [train_size, test_size])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6TngIOjGhuyz"},"outputs":[],"source":["# Collect and mix the data in [^2]\n","train_dataloader_2d = DataLoader(dataset = x_train_2d, shuffle = True, batch_size = 50)\n","test_dataloader_2d = DataLoader(dataset = x_test_2d, shuffle = True, batch_size = 50)\n","train_dataloader_3d = DataLoader(dataset = x_train_3d, shuffle = True, batch_size = 50)\n","test_dataloader_3d = DataLoader(dataset = x_test_3d, shuffle = True, batch_size = 50)\n","train_dataloader_nu = DataLoader(dataset = x_train_nu, shuffle = True, batch_size = 50)\n","test_dataloader_nu = DataLoader(dataset = x_test_nu, shuffle = True, batch_size = 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EAVHT7-Fhuyz"},"outputs":[],"source":["# Load ground truth data to GPU\n","y_train = y_train_ordered.to(device)\n","y_train_3d = y_train.view(int(len(y_train)), int(len(y_train[0])), int(len(y_train[0][0])/14), 14)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U45wDpVlhuy0","executionInfo":{"status":"ok","timestamp":1725462606566,"user_tz":-120,"elapsed":12,"user":{"displayName":"Stefan R","userId":"05111927381768976267"}},"outputId":"e230b836-12c5-43c4-cff9-f914cd7bcb2a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["# Define the Encoder-Decoder networks\n","## FFN | Inputs: input_dim, hidden dim\n","encoder_ffn = architectures.Encoder_FFN(three_d_shape[1], 150)\n","decoder_ffn = architectures.Decoder_FFN((max_y_length*14), 150)\n","ffn_ed_model = architectures.Seq2Seq(encoder_ffn, decoder_ffn, device)\n","## LSTM | Inputs: input_dim, embedding dim, hidden dim, nr layers, droput\n","encoder_lstm = architectures.Encoder_LSTM(three_d_shape[1], 150, 150, 2, 0.5)\n","decoder_lstm = architectures.Decoder_LSTM(14, 150, 150, 3, 0.5)\n","lst_ed_model = architectures.Seq2Seq(encoder_lstm, decoder_lstm, device)\n","## Transformer | Inputs: input_dim, embedding dim, hidden dim, nr layers, droput\n","encoder_tra = architectures.TransformerEncoder(three_d_shape[1], 150, 5, 150, 1, dropout=0.1)\n","decoder_tra = architectures.TransformerDecoder(14, 150, 1, 150, 3)\n","tra_ed_model = architectures.Seq2SeqTransformer(encoder_tra, decoder_tra, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhgQ83snhuy1"},"outputs":[],"source":["# Define optimizers for models\n","lr = 0.001\n","ffn_ed_optimizer = torch.optim.Adam(ffn_ed_model.parameters(),lr=lr)\n","lst_ed_optimizer = torch.optim.Adam(lst_ed_model.parameters(),lr=lr)\n","tra_ed_optimizer = torch.optim.Adam(tra_ed_model.parameters(),lr=lr)"]},{"cell_type":"markdown","metadata":{"id":"wKXra33Shuy2"},"source":["# 4 Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2n3Y17IQhuy2"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"3hBnT5_ghuy2"},"source":["## 4.1 Encoder-Decoder Networks"]},{"cell_type":"markdown","metadata":{"id":"MmucGvSRhuy3"},"source":["### 4.1.1 FFN Encoder-Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQp2HOrqhuy3"},"outputs":[],"source":["# Load model to GPU\n","ffn_ed_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYEVzXU_huy3"},"outputs":[],"source":["# Train model and save results\n","FFN_CELtrain, FFN_CELtest, FFN_ACCtrain, FFN_ACCtest = schedule.train_model(ffn_ed_model, train_dataloader_nu, test_dataloader_nu, ffn_ed_optimizer, criterion, 50, device, max_y_length, y_train)\n","torch.save(ffn_ed_model.state_dict(), 'addition_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2XZkrYzhuy4"},"outputs":[],"source":["# A sanity test for wheter the outputs look appropriate\n","schedule.sanity(ffn_ed_model, test_dataloader_nu, device, max_y_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ta53-qz8huy4"},"outputs":[],"source":["# Delete model from GPU to make space for new models\n","del ffn_ed_model\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"udcLmIHzhuy7"},"source":["### 4.1.3 LSTM Encoder-Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILguj_yZhuy7"},"outputs":[],"source":["# Load model to GPU\n","lst_ed_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kpjPHL8huy7"},"outputs":[],"source":["# Training Loop\n","LSTM_CELtrain, LSTM_CELtest, LSTM_ACCtrain, LSTM_ACCtest = schedule.train_model(lst_ed_model, train_dataloader_nu, test_dataloader_nu, lst_ed_optimizer, criterion, 50, device, max_y_length, y_train_3d)\n","torch.save(lst_ed_model.state_dict(), 'addition_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5r3s-H6Dhuy8"},"outputs":[],"source":["# A sanity test for wheter the outputs look appropriate\n","schedule.sanity(lst_ed_model, test_dataloader_nu, device, max_y_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2k1YM1edhuy8"},"outputs":[],"source":["# Delete model from GPU to make space for new models\n","del lst_ed_model\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"zN9VmQ6Bhuy9"},"source":["### 4.1.4 Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvAMoRG5huy_","outputId":"e3af46cb-5f9a-45a7-8d92-ab089833a5c9","executionInfo":{"status":"ok","timestamp":1725461637641,"user_tz":-120,"elapsed":1020,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'architectures' from '/content/master-s-thesis-finished/architectures.py'>"]},"metadata":{},"execution_count":17}],"source":["importlib.reload(architectures)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGKt62vXhuzA"},"outputs":[],"source":["# Load model to GPU\n","tra_ed_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpKpuJ6YhuzB","outputId":"db872141-5a3c-4762-93a3-c607091ca8be","executionInfo":{"status":"ok","timestamp":1725461678946,"user_tz":-120,"elapsed":33775,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ep. 01, CEL-Train: 0.9663| CEL-Test: 0.5746 | ACC-Train: 0.8750 | ACC-Test:  0.8239\n"]}],"source":["TRA_CELtrain, TRA_CELtest, TRA_ACCtrain, TRA_ACCtest = schedule.train_model(tra_ed_model, train_dataloader_nu, test_dataloader_nu, tra_ed_optimizer, criterion, 50, device, max_y_length, y_train_3d)\n","torch.save(tra_ed_model.state_dict(), 'addition_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ovVY3cvqhuzC"},"outputs":[],"source":["# A sanity test for wheter the outputs look appropriate\n","schedule.sanity(tra_ed_model, test_dataloader_nu, device, max_y_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9VJHWwKhuzC"},"outputs":[],"source":["# Delete model from GPU to make space for new models\n","del tra_ed_model\n","torch.cuda.empty_cache()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[{"file_id":"1C5oz71tKYN4Z2iJlJprh6-IribH-Rp0u","timestamp":1725462724501},{"file_id":"https://github.com/stereifberger/master-s-thesis-finished/blob/new-cleaned-branch/implementation.ipynb","timestamp":1725462360636}],"gpuType":"L4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}